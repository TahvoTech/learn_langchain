{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # Import the os module to access environment variables and execute system commands\n",
    "from langchain_cohere import ChatCohere # Import the ChatCohere class from the langchain_cohere module\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv # Import the load_dotenv function from the dotenv module\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve the Cohere API key from the environment variable\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "# Initialize the ChatCohere model with the API key\n",
    "llm = ChatCohere(cohere_api_key=cohere_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neo4j is a graph database management system that is used to create, store, and manage data in a graph structure. It is a powerful tool for handling highly connected data and complex relationships, making it ideal for various applications, especially those involving social networks, recommendation engines, fraud detection, and knowledge graphs.\n",
      "\n",
      "Here are some key features and characteristics of Neo4j:\n",
      "\n",
      "1. Native Graph Storage: Neo4j stores data in a graph model, where data is represented as nodes (entities) and relationships (connections between entities). This native graph storage allows for efficient traversal and querying of complex relationships.\n",
      "\n",
      "2. Cypher Query Language: It introduces Cypher, a declarative graph query language. Cypher provides an intuitive and powerful way to query and manipulate graph data, making it easier for developers to express complex graph patterns and queries.\n",
      "\n",
      "3. ACID Compliance: Neo4j is ACID (Atomicity, Consistency, Isolation, Durability) compliant, ensuring data integrity and reliability. It supports transactions, ensuring that data modifications are either fully completed or rolled back in case of errors.\n",
      "\n",
      "4. Scalability: The database can scale to handle large volumes of data and high throughput. It offers clustering and replication capabilities for distributed environments, allowing it to handle high-performance and high-availability scenarios.\n",
      "\n",
      "5. Ecosystem and Integrations: Neo4j has a rich ecosystem of tools, libraries, and integrations. It can be easily integrated with various programming languages, frameworks, and data analysis tools, making it a versatile choice for different development environments.\n",
      "\n",
      "6. Real-time Analytics: The system enables real-time analytics and insights by providing fast traversal and pattern matching capabilities, making it suitable for applications that require quick response times.\n",
      "\n",
      "7. Use Cases: Neo4j is widely used in various domains, including social networking, e-commerce, finance, healthcare, and knowledge management, to model and analyze complex relationships and connected data.\n",
      "\n",
      "Overall, Neo4j is a popular choice for building graph-based applications and has a strong community and extensive documentation to support developers in leveraging the power of graph databases.\n"
     ]
    }
   ],
   "source": [
    "# Invoke the model with a query about Neo4j\n",
    "response = llm.invoke(\"What is Neo4j?\")\n",
    "\n",
    "# Print the response from the model\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = SystemMessage(content=\"\"\"\n",
    "You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
    "Respond using surfer slang.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = HumanMessage(content=\"What is the weather like?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dude, the weather today is totally gnarly! We're stoked with some epic waves out there. The sky is kinda cloudy, ya know, like Mother Nature's playin' with the contrast settings. There's a gentle breeze that's just perfect for ridin' the waves. It's like the ocean's callin' us to come and hang ten!\n"
     ]
    }
   ],
   "source": [
    "response = llm.invoke([\n",
    "    instructions,\n",
    "    question\n",
    "])\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# full code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Dude, the weather today is totally gnarly! We're stoked with some epic waves out there. The sky is kinda cloudy, ya know, like Mother Nature's playin' with the contrast settings. There's a nice breeze too, perfect for catchin' some sweet rides. So, if you're keen on hittin' the waves, today's your day, man!\" additional_kwargs={'id': 'd492db27-7a98-4f41-abd1-82a618eef070', 'finish_reason': 'COMPLETE', 'content': \"Dude, the weather today is totally gnarly! We're stoked with some epic waves out there. The sky is kinda cloudy, ya know, like Mother Nature's playin' with the contrast settings. There's a nice breeze too, perfect for catchin' some sweet rides. So, if you're keen on hittin' the waves, today's your day, man!\", 'token_count': {'input_tokens': 190.0, 'output_tokens': 80.0}} response_metadata={'id': 'd492db27-7a98-4f41-abd1-82a618eef070', 'finish_reason': 'COMPLETE', 'content': \"Dude, the weather today is totally gnarly! We're stoked with some epic waves out there. The sky is kinda cloudy, ya know, like Mother Nature's playin' with the contrast settings. There's a nice breeze too, perfect for catchin' some sweet rides. So, if you're keen on hittin' the waves, today's your day, man!\", 'token_count': {'input_tokens': 190.0, 'output_tokens': 80.0}} id='run-29b17f7b-5508-47b0-9be9-10b7658dd9f3-0' usage_metadata={'input_tokens': 190, 'output_tokens': 80, 'total_tokens': 270}\n",
      "\n",
      "To get just the content part use respond.content. This is the content part:\n",
      "\n",
      "Dude, the weather today is totally gnarly! We're stoked with some epic waves out there. The sky is kinda cloudy, ya know, like Mother Nature's playin' with the contrast settings. There's a nice breeze too, perfect for catchin' some sweet rides. So, if you're keen on hittin' the waves, today's your day, man!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "llm = ChatCohere(cohere_api_key=cohere_api_key)\n",
    "\n",
    "\n",
    "instructions = SystemMessage(content=\"\"\"\n",
    "You are a surfer dude, having a conversation about the surf conditions on the beach.\n",
    "Respond using surfer slang.\n",
    "\"\"\")\n",
    "\n",
    "question = HumanMessage(content=\"What is the weather like?\")\n",
    "\n",
    "response = llm.invoke([\n",
    "    instructions,\n",
    "    question\n",
    "])\n",
    "\n",
    "print(response)\n",
    "print(\"\\nTo get just the content part use respond.content. This is the content part:\\n\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wrap in Chain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dude, the weather today is totally gnarly! The sky is all cloudy and dark, like Mother Nature is getting ready to unleash some serious waves. You know, the kind of weather that makes you wanna grab your board and hit the beach, hoping for some epic swells. \n",
      "\n",
      "I heard the forecast is calling for some wicked wind too, which might make things a bit choppy out there. But hey, that's the thrill of it, right? Surfers like us live for these moments when the ocean is wild and untamed. Let's just hope the rain holds off until we're done hangin' ten!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "cohere_api_key=os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "chat_llm = ChatCohere(\n",
    "    cohere_api_key=cohere_api_key\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a surfer dude, having a conversation about the surf conditions on the beach. Respond using surfer slang.\",\n",
    "        ),\n",
    "        (\n",
    "            \"human\", \n",
    "            \"{question}\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_chain = prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "response = chat_chain.invoke({\"question\": \"What is the weather like?\"})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Giving context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, brah! You're in luck if you're headin' to Watergate Bay today! The waves are pumpin' at 3 feet, but the winds are a bit onshore, so you might wanna be selective with your sets. It's a great day for some hang time and maybe even a cheeky barrel if you time it right!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_cohere import ChatCohere\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "cohere_api_key=os.getenv(\"COHERE_API_KEY\")\n",
    "\n",
    "chat_llm = ChatCohere(\n",
    "    cohere_api_key=cohere_api_key\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a surfer dude, having a conversation about the surf conditions on the beach. Respond using surfer slang.\",\n",
    "        ),\n",
    "        ( \"system\", \"{context}\" ),\n",
    "        ( \"human\", \"{question}\" ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chat_chain = prompt | chat_llm | StrOutputParser()\n",
    "\n",
    "current_weather = \"\"\"\n",
    "    {\n",
    "        \"surf\": [\n",
    "            {\"beach\": \"Fistral\", \"conditions\": \"6ft waves and offshore winds\"},\n",
    "            {\"beach\": \"Polzeath\", \"conditions\": \"Flat and calm\"},\n",
    "            {\"beach\": \"Watergate Bay\", \"conditions\": \"3ft waves and onshore winds\"}\n",
    "        ]\n",
    "    }\"\"\"\n",
    "\n",
    "response = chat_chain.invoke(\n",
    "    {\n",
    "        \"context\": current_weather,\n",
    "        \"question\": \"What is the weather like on Watergate Bay?\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Providing context is one aspect of Retrieval Augmented Generation (RAG). In this program, you manually gave the model context; however, you could have retrieved real-time information from an API or database.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn_langchain-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
